---
title: "VI. Lazy Learning"
author-meta: "Sampo Suzuki"
pagetitle: "DAWS2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)

htmltools::tagList(rmarkdown::html_dependency_font_awesome())

require(tidyverse)

seed <- 300
RNGversion("3.5.3")
```

　  
　HS650 第6章 [Lazy Learning - Classification Using Nearest Neighbors <i class="fa fa-external-link"></i>](http://www.socr.umich.edu/people/dinov/courses/DSPA_notes/06_LazyLearning_kNN.html){target="_blank" title="UMich HS650"} （以降、テキスト）では遅延学習を扱っています。  

　  

# Case Study
　HS650 第6章 Lazy Learning 第3節のケーススタディは若者の発育に関するもので、データは全て **シミュレーションにより作成されたデータ** が用いられています。データは第6章のページのリンクから入手してください。  

　また、本ページではテキストで使用していない以下の追加パッケージを用いています。  

Package      | Version   | Descriptions
-------------|-----------|------------------------------------------------------
skimr        | `r packageVersion('skimr')` | Compact and Flexible Summaries of Data
tidyverse    | `r packageVersion('tidyverse')` | Easily Install and Load the 'Tidyverse'

　  

## Collecting Data
　データファイルとして以下のファイルが提供されています。区切り文字が異なりますのでカンマ区切りのファイルを利用することをおすゝめします。  
　  

ファイル名                       | 区切り          | 備考
---------------------------------|-----------------|----------------------------
CaseStudy02_Boystown_Data.csv    | スペース区切り  | `read.csv` 関数にオプション指定で読み込み可
CaseStudy02_Boystown_Data_V2.csv | カンマ区切り    | 

　  

```{r, echo=FALSE}
x <- "./data/UMichi/CaseStudy02_Boystown_Data_V2.csv" %>% 
  read.csv()
```

　各変数(フィーチャー）は以下のような内容になっています。詳細はデータファイルと共に提供されている Word ファイル（CaseStudy02_Boystown_V2.docx）を参照してください。  
　  

feature    | 内容                       | 取りうる値
-----------|----------------------------|----------------------------
id         | インスタンスの識別子       | N/A
sex        | 性別                       | 1: male, 2: female
gpa        | （米国の）成績評価値の平均 | 0: A, 1: B, ... 5: F(不可)
Alcoholuse | 飲酒頻度                   | 0: drink everyday, ... 11: never drinked
alcatt     | 家庭における飲酒許容       | 0: approve, ... 6: disapprove 
dadjob     | 父親の就業                 | 1: yes, 2: no
momjob     | 母親の就業                 | 1: yes, 2: no
dadclose   | 父親との親密度             | 0: usually, ... 7: never
momclose   | 母親との親密度             | 0: usually, ... 7: never
larceny    | $50以上の窃盗行為          | 0: never, ... 4: many times  
vandalism  | 破壊行為                   | 0: never, ... 4: many times

　  
　`id` を除く各変数は離散値（名義尺度または順序尺度）になっていますので、ダミーコーディングなどを利用して変換する必要がありそうです。  

　  

## Exploring and preparing the data
　データは全て数値データですが`id`は単なる識別番号なのでトレーニング（学習）やテスト（分類）には利用しませんので外す必要があります（行名 `rowname` としても構いません）。なお、データファイルはデータフレーム型変数 `x` に読み込んであるものとします。
```{r}
skimr::skim(x)
```

　  
　性別と親の就業状況が `1/2` データですので `0/1` データに変換しておきます。就業状況は未就業の場合に `0` とするため少しややこしい計算をしています。
```{r}
df <- x %>% 
  dplyr::mutate(sex = sex - 1L,                 # 0: male,  1: female
                dadjob = -1L * (dadjob - 2L),   # 0: nojob, 1: has job
                momjob = -1L * (momjob - 2L))   # 0: nojob, 1: has job
df
```

　  
　続いてラベル変数となる成績区分（`grade`）を成績の平均評価（`gpa`）から作成します。「成績上位（above = A, B, C）」と「成績下位（below = D, E, F）」というラベルにします。なお、ラベルとなる変数はデータフレーム型変数でなくベクトル型変数にしておきます。
```{r}
df_train_label <- df %>% 
  dplyr::select(gpa) %>% 
  dplyr::slice(1:150) %>% 
  dplyr::mutate(grade = gpa %in% c(3, 4, 5) %>% 
                  as.factor() %>%
                  forcats::fct_recode(`成績下位` = "TRUE", `成績上位` = "FALSE")) %>% 
  .$grade
df_train_label

df_test_label <- df %>% 
  dplyr::select(gpa) %>% 
  dplyr::slice(151:200) %>% 
  dplyr::mutate(grade = gpa %in% c(3, 4, 5) %>% 
                  as.factor() %>%
                  forcats::fct_recode(`成績下位` = "TRUE", `成績上位` = "FALSE")) %>% 
  .$grade
df_test_label
```

　  

## Normalizing Data
　各変数に最小最大正規化を適用するために正規化関数を定義しておきます。『MLwR 2nd』の第3章と異ななり念のために欠損値対策などを入れてあります。  
　  

```{r}
normalize <- function(x = NULL) {
  if (!is.null(x)) {
    return((x - min(x, na.rm = TRUE)) / diff(range(x, na.rm = TRUE)))
  } else {
    return(NA)
  }
}
```

　  

## Data preparation - creating training and test datasets
　では、定義した正規化関数を用いて対象データセットの各変数を正規化しトレーニング用とテスト用のインスタンスを作成します。なお、前述のように `id` は単なる識別情報でトレーニング・テストともに不要ですので `rowname` に変換しておきます。
　データの分割は単純に先頭の $150$ インスタンスをトレーニング用、残りの $50$ インスタンスをテスト用としています。
```{r}
df_train <- df %>% 
  dplyr::mutate(id = as.character(id)) %>% 
  dplyr::mutate_if(is.numeric, .funs = normalize) %>% 
  dplyr::slice(1:150) %>% 
  tibble::column_to_rownames(var = "id")
df_train

df_test <- df %>% 
  dplyr::mutate(id = as.character(id)) %>% 
  dplyr::mutate_if(is.numeric, .funs = normalize) %>% 
  dplyr::slice(151:200) %>% 
  tibble::column_to_rownames(var = "id")
df_test
```

　  

## Training a model on the data
## Evaluating model performance
　`class::knn`関数を用いてトレーニングを行い、その結果をクロス集計により評価します。なお、近傍数 $k$ はトレーニング用インスタンス数の平方根（`r sqrt(150)`）に最も近い整数とします。
```{r}
set.seed(seed)
result <- class::knn(train = df_train, test = df_test, cl = df_train_label,
                     k = 12) %>% 
  caret::confusionMatrix(reference = df_test_label, positive = "成績下位")
result
```

　評価の結果、正解率（Accuracy）を見る限り $`r result$overall[1]`$ とまずまずのモデルだと思われます。  

　  

## Improving model performance
　パフォーマンス改善を模索するために各フィーチャーをZスコア化してみます。ラベルデータはそのまま用います。
```{r}
df_train_z <- df %>% 
  dplyr::mutate(id = as.character(id)) %>% 
  dplyr::mutate_if(is.numeric, .funs = scale) %>% 
  dplyr::slice(1:150) %>% 
  tibble::column_to_rownames(var = "id")
df_train_z

df_test_z <- df %>% 
  dplyr::mutate(id = as.character(id)) %>% 
  dplyr::mutate_if(is.numeric, .funs = scale) %>% 
  dplyr::slice(151:200) %>% 
  tibble::column_to_rownames(var = "id")
df_test
```

```{r}
set.seed(seed)
result <- class::knn(train = df_train_z, test = df_test_z, cl = df_train_label,
                     k = 12) %>% 
  caret::confusionMatrix(reference = df_test_label, positive = "成績下位")
result
```

　  

## Testing alternative values of $k$
　では、近傍数（$k$）はいくつが最適なのでしょうか？最小最大正規化したインスタンスを用いて交差検証（Cross Varidation）で確認してみます。
```{r}
set.seed(seed)
result <- caret::train(x = df_train, y = df_train_label,
                      method = "knn", tuneGrid = expand.grid(k = c(1:20)),
                      trControl = caret::trainControl(method = "cv"))
result
```

```{r}
result %>% ggplot2::ggplot()
```

　テキストとは異なる $k = `r result$bestTune$k`$ がベストパラメータとなりました。  
　可視化については省略しますので読者の皆さんが試してみてください。  

　  

## Quantitative Assessment
　省略しますので読者の皆さんが試してみてください。  

　  

# ケーススタディに対する疑問
　HS650 の kNN に関するケーススタディでは、成績評価の平均である `gpa` 変数を基にした `grade` 変数を作成し分類のためのラベルとして利用しています。しかし、トレーニング用、テスト用の両インスタンスに `gpa` を残したまま利用しています。`grade` と `gpa` は表現を変えただけの同一変数ですので、`gpa` を使う限り正解率が高くなるのは当然ではないでしょうか？  
　  
　そこで、トレーニング用、テスト用インスタンスから `gpa` 変数を除き最大正規化したインスタンスを用いた分類を行ってみます。
```{r}
df_train_nogpa <- df %>% 
  dplyr::select(-gpa) %>% 
  dplyr::mutate(id = as.character(id)) %>% 
  dplyr::mutate_if(is.numeric, .funs = scale) %>% 
  dplyr::slice(1:150) %>% 
  tibble::column_to_rownames(var = "id")
df_train_nogpa

df_test_nogpa <- df %>% 
  dplyr::select(-gpa) %>% 
  dplyr::mutate(id = as.character(id)) %>% 
  dplyr::mutate_if(is.numeric, .funs = scale) %>% 
  dplyr::slice(151:200) %>% 
  tibble::column_to_rownames(var = "id")
df_test_nogpa
```

```{r}
set.seed(seed)
result <- class::knn(train = df_train_nogpa, test = df_test_nogpa,
                     cl = df_train_label, k = 12) %>% 
  caret::confusionMatrix(reference = df_test_label, positive = "成績下位")
result
```

　上記の結果となりました。これが何を意味するかは読者の皆さんが考えてみてください。  

　  

# 参考資料
* [Lazy Learning - Classification Using Nearest Neighbors <i class="fa fa-external-link"></i>](http://www.socr.umich.edu/people/dinov/courses/DSPA_notes/06_LazyLearning_kNN.html){target="_blank" title="University of Michigan: Data Science and Predictive Analytics (UMich HS650)"} 
* [Assignment 6: Lazy Learning - Classification Using Nearest Neighbors <i class="fa fa-external-link"></i>](http://www.socr.umich.edu/people/dinov/courses/DSPA_notes/06_LazyLearning_kNN_Assignment.html){target="_blank" title="University of Michigan: Data Science and Predictive Analytics (UMich HS650)"} 
* [Python と R の違い (k-NN 法による分類器) <i class="fa fa-external-link"></i>](https://pythondatascience.plavox.info/python%E3%81%A8r%E3%81%AE%E9%81%95%E3%81%84/k-nn%E6%B3%95＊){target="_blank" title="Python でデータサイエンス"} 
* [Variation on “How to plot decision boundary of a k-nearest neighbor classifier from Elements of Statistical Learning?” <i class="fa fa-external-link"></i>](https://stackoverflow.com/questions/31234621/variation-on-how-to-plot-decision-boundary-of-a-k-nearest-neighbor-classifier-f){target="_blank" title="stack overflow"}
* [Chapter 3 Overview of Statistical Learning <i class="fa fa-external-link"></i>](https://dereksonderegger.github.io/578/3-overview-of-statistical-learning.html){target="_blank" title="STA 578 - Statistical Computing Notes"} 
* [機械学習（caret package） <i class="fa fa-external-link"></i>](https://iisssseeiiii.hatenablog.com/entry/20101022/1287735709){target="_blank" title="おしゃスタ統計 〜統計学・機械学習・AI〜"} 

　  

<center> [Back](./mlwr_c03.html){title="第3章 遅延学習 - 最近傍法を使った分類"} </center>

---
<center> [CC BY-NC-SA 4.0 <i class="fa fa-external-link"></i>](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja), Sampo Suzuki [`r format(Sys.time(), format = '%F(%Z)')`] </center>